---
title: "Mixed Effects Modelling"
output: html_document
---

The following libraries are used for modelling, data cleaning and wrangling, and visualizing. If not already installed, uncomment the 'install.packages(...)' code to install them and then run librayr(...).
```{r}
#install.packages('lme4')
#install.packages('tidyverse')
#install.packages('janitor')
#install.packages('ggplot2')
library('lme4')
library(tidyverse)
library(janitor)
library(ggplot2)
```

This reads in the finalized data table with all variables.
```{r}
data <- read.csv('~/Documents/GitHub/capstone-accenture/clean_data/fireClimateHumanTable4_editted.csv')
```

We add an indicator variable summer_month for whether the record is in the summer season or not (June, July, or August).
```{r}
data <- data %>%
  mutate(summer_month = substr(time, 6, 7) == '06' | substr(time, 6, 7) == '07' | substr(time, 6, 7) == '08')
```


At first, only including county as a random effect to control for the correlation between neighboring counties.
We want to know if an association exists between predictors and response variable after controlling for the variation in county.
Using lmer (meaning the response variable is expected to follow a Gaussian distribution) to compare against glmer later (with a Poisson distribution).
```{r}
mixed.lmer <- lmer(count ~ X2m_temperature + total_precipitation + low_vegetation_cover + X10m_wind_speed + volumetric_soil_water_layer_1 + total_cloud_cover + populationdensity + summer_month + (1|county), data = data)
summary(mixed.lmer)
```

Now standardizing numeric predictors to ensure they are all comparable.
```{r}
temp_data <- scale(data[,9:17])
data[,9:17] <- temp_data
```

Using glmer to specify Poisson response variable and two random effects for county (spatial) and month (temporal). This set of predictors was decided from cross validation performed below.
```{r}
finalized_model <- glmer(formula=count ~ X2m_temperature + low_vegetation_cover + X10m_wind_speed  + populationdensity + (1|county) + (1|month_factor), data = data, family='poisson')
```



Before performing k-fold cross validation, we wanted to take a look at just one train/test split with testing on 2019. 
Creating training split for testing on 2019.
```{r}
test_2019 <- data %>%
   subset(year==2019)
train_2019 <- data %>%
   subset(year!=2019)
```

Training the model specifically on train_2019, for predicting on 2019.
```{r}
model2019 <- glmer(formula=count ~ X2m_temperature + low_vegetation_cover + X10m_wind_speed  + populationdensity + (1|county) + (1|month_factor), data = train_2019, family='poisson')
```

Making predictions for test_2019 data.
```{r}
pred2019 <- exp(predict(model2019, test_2019))
summary(exp(pred2019))
```

To evaluate how close we were to actual counted values, we calculate MSE.
```{r}
mse <- 0
pred2019 <- as.vector(pred2019)
for(i in 1:length(test_2019)){
   mse = mse + (test_2019$count[i] - pred2019[i])**2
}
mse = mse/length(test_2019)
```

Rescaling population density predictor.
```{r}
data<-data %>%
   mutate(populationdensity = populationdensity/10)
```

Performs k-fold cross validation with a fold for each year in our time range. Subsets the data into train/test split, trains model on train split, predicts on test split, calculates MSE which is aggregated into an overall MSE. We divide the aggregeated MSE in the end by 7 since there are 7 years in our time range, to get a final average MSE.
```{r}
total_mse <- 0
for (y in 2013:2019){
    train<- data %>%
      subset(year!=y)
    test<-data %>%
      subset(year==y)
    model <- glmer(formula=count ~ X2m_temperature + low_vegetation_cover + X10m_wind_speed                            + populationdensity + (1|county) + (1|month_factor), 
                   data = train, family='poisson')
    pred <- predict(model, test)
    mse <- 0
    preds <- as.vector(pred)
    for(i in 1:length(test)){
       mse = mse + (test$count[i] - exp(preds[i]))**2
    }
    total_mse = total_mse + mse/length(test)
}
total_mse/7
```

The following code forecasts for two situations: one county (Riverside) for all months in 2019, and all counties for one month and year (July 2019).

We've trained the model on data from 2013 to 2018, for predictions on 2019.

Forecasting for a specific county (Riverside), across all months in 2019:
```{r}
county_data = data %>% 
    subset(data$county == 'Riverside')
pred_riverside <- as.vector(exp(predict(finalized_model, county_data)))
county_data["predicted_count"] <- pred_riverside
write.csv(county_data, "randomEffectsCountyPrediction_Riverside.csv")
```

Forecasting for a specific month and year (July 2017), across all counties. We write the results to a csv for later visualization.
```{r}
month_data <- data %>% 
    subset(month_factor == 6 & year == 2019)

non_month <- data %>%
   subset(month_factor != 6 & year != 2019)

model <- glmer(formula=count ~ X2m_temperature + low_vegetation_cover + X10m_wind_speed                            + populationdensity + (1|county) + (1|month_factor), 
                   data = data, family='poisson')

pred <- predict(model, month_data, allow.new.levels = TRUE)

mse <- 0
preds <- as.vector(pred)
for(i in 1:length(test)){
 mse = mse + (test$count[i] - exp(preds[i]))**2
}

month_data["predicted_count"] <- pred_july
write.csv(month_data, "randomEffectsMonthPrediction_July.csv")
```

